{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f504c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# get api key from .env file \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fb8f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read biases from bias_explanantions folder\n",
    "\n",
    "with open(\"bias_explanations/anchoring.txt\", \"r\") as f:\n",
    "    anchoring = f.read()\n",
    "\n",
    "with open(\"bias_explanations/status_quo.txt\", \"r\") as f:\n",
    "    status_quo = f.read()\n",
    "\n",
    "with open(\"bias_explanations/risk_aversion.txt\", \"r\") as f:\n",
    "    risk_aversion = f.read()\n",
    "\n",
    "with open(\"bias_explanations/endowement.txt\", \"r\") as f:\n",
    "    endowment = f.read()\n",
    "\n",
    "with open(\"bias_explanations/decoy.txt\", \"r\") as f:\n",
    "    decoy = f.read()\n",
    "\n",
    "with open(\"bias_explanations/framing.txt\", \"r\") as f:\n",
    "    framing = f.read()\n",
    "\n",
    "with open(\"bias_explanations/sunk_cost.txt\", \"r\") as f:\n",
    "    sunk_cost = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad9bf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_subdomains = [\n",
    "    \"Medication/Prescription Management\",\n",
    "    \"Vaccination\",\n",
    "    \"Doctor/Clinic Selection\",\n",
    "    \"Medical Procedure/Treatment Choices\",\n",
    "    \"Organ Donation & Consent\",\n",
    "    \"Health Data Sharing\",\n",
    "    \"Health Insurance\",\n",
    "    \"Medical App Usage\",\n",
    "    \"Supplement/Over-the-Counter Products\",\n",
    "    \"Fitness/Wellness Programs\"\n",
    "]\n",
    "\n",
    "\n",
    "eeducation_subdomains = [\n",
    "    \"Course/Subject Selection\",\n",
    "    \"Exam & Study Choices\",\n",
    "    \"Assignment/Grading\",\n",
    "    \"Scholarship/Program Application\",\n",
    "    \"Group Project Leadership\",\n",
    "    \"Student Behavior Interpretation\",\n",
    "    \"Academic Event Participation\",\n",
    "    \"College/Internship Applications\"\n",
    "]\n",
    "\n",
    "ecommerce_subdomains = [\n",
    "    \"Product Purchase Decisions\",\n",
    "    \"Subscription Services\",\n",
    "    \"Return/Refund Policies\",\n",
    "    \"Bundle Purchases\",\n",
    "    \"Flash Sales/Promotions\",\n",
    "    \"Warranty/Insurance Add-Ons\",\n",
    "    \"Influencer Recommendations\",\n",
    "    \"Sweepstakes & Loyalty Programs\",\n",
    "    \"Shipping & Delivery Choices\"\n",
    "]\n",
    "\n",
    "domain_list = [\"education and learning\", \"ecommerce\", \"healthcare and medical evaluation\"]\n",
    "bias_list = ['Anchoring Bias', 'status quo', 'risk aversion', 'endowement effect', 'decoy effect', 'framing effect', 'sunk cost fallacy']\n",
    "bias_explanantions = [anchoring, status_quo, risk_aversion, endowment, decoy, framing, sunk_cost]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_scenario(bias_type, domain, subdomains, bias_description):\n",
    "    prompt = f\"\"\"\n",
    "I am designing a psychological experiment to test {bias_type}.\n",
    "\n",
    "The field is {domain}. The subdomains are {subdomains}. Select the best subdomain for this experiment.\n",
    "\n",
    "This bias is described as: {bias_description}\n",
    "\n",
    "Please generate a realistic scenario around 4-5 sentences total where a person is asked to **rate something on a scale of 1 to 7.**\n",
    "The context should have a readability level of a 6th grader and be relatable to a general audience.\n",
    "\n",
    "There should be:\n",
    "\n",
    "- A biased condition where the framing activates the bias,\n",
    "- And a control condition with neutral framing.\n",
    "\n",
    "The biased and control scenarios should describe the **same situation** but the framing should differ to test the bias.\n",
    "\n",
    "At the end of each scenario, include a **clear rating question** that asks what the participants think I SHOULD DO in this situation on a scale of 1 to 7 (i.e. recommend to take action or not)\n",
    "\n",
    "Ensure the scenario is written in the first person (I).\n",
    "\n",
    "Provide the response in a **structured format**, keeping it simple and clear, like this:\n",
    "\n",
    "Biased condition:\n",
    "\n",
    "[Short description of the scenario (around 3-4 sentences)]  \n",
    "[Rating question prompt]\n",
    "\n",
    "Control condition:\n",
    "\n",
    "[Short description of the scenario (around 3-4 sentences)]  \n",
    "[Rating question prompt]\n",
    "\n",
    "Finally, include your explanation of why this scenario is a good example of the bias.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant skilled at creating psychological experiment scenarios.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_scenario_with_parameters(base_scenario_text, bias_type, domain):\n",
    "    prompt = f\"\"\"\n",
    "I have the following scenario:\n",
    "\n",
    "{base_scenario_text}\n",
    "\n",
    "This scenario is generated to test {bias_type} in the context of {domain}.\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1. First, generate a list of possible parameters (in the format {{parameter_name}}) that could be used to make this scenario richer and more flexible.\n",
    "For each parameter, provide a few possible values (e.g., parameter_name: [value1, value2, value3]).\n",
    "\n",
    "2. Then, select at least 4 parameters from your list that fit best.\n",
    "\n",
    "3. Edit the scenario text to include those 4 parameters as placeholders (e.g., \"I am testing a {{medication_type}} from a {{pharmacy_type}}.\").\n",
    "\n",
    "The scenario should keep the same structure as before:\n",
    "- A short description (3-4 sentences),\n",
    "- Followed by the rating question.\n",
    "\n",
    "Do NOT change the structure of the scenario.\n",
    "\n",
    "At the end, provide:\n",
    "- The revised scenario (with parameters inserted, same structure),\n",
    "- The list of parameters and their possible values (formatted as Python lists).\n",
    "\n",
    "Make sure the parameters are meaningful but not too complex, and all combinations make sense in the scenario context.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant skilled at enriching psychological experiment scenarios with parameters.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 3 subdomains from the health subdomains\n",
    "import random\n",
    "\n",
    "# create a new dataframe to store the scenarios with columns bias, domain, subdomain, scenario, enriched_scenario\n",
    "df = pd.DataFrame(columns=[\"bias\", \"domain\", \"subdomain\", \"scenario\", \"enriched_scenario\"])\n",
    "\n",
    "# get education scenarios\n",
    "domain = \"education and learning\"\n",
    "\n",
    "\n",
    "for i, bias_type in enumerate(bias_list):\n",
    "    # randomly select 3 subdomains from the health subdomains\n",
    "    random_subdomains = random.sample(eeducation_subdomains, 3)\n",
    "\n",
    "    # generate a scenario\n",
    "    scenario = generate_base_scenario(bias_type=bias_type, domain=domain, subdomains=random_subdomains, bias_description=bias_explanantions[i])\n",
    "\n",
    "    # enrich the scenario with parameters\n",
    "    enriched_scenario = enrich_scenario_with_parameters(scenario, bias_type=bias_type, domain=domain)\n",
    "\n",
    "    # create a python dictionary to store the scenario \n",
    "    scenario_dict = {\n",
    "        \"bias\": bias_type,\n",
    "        \"domain\": domain,\n",
    "        \"subdomain\": random_subdomains,\n",
    "        \"scenario\": scenario,\n",
    "        \"enriched_scenario\": enriched_scenario\n",
    "    }\n",
    "\n",
    "    # add the scenario to the dataframe\n",
    "    df = pd.concat([df, pd.DataFrame([scenario_dict])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "34bd30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to a csv file\n",
    "df.to_csv(\"scenarios.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
